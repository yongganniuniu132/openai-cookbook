{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assistants API Overview\n",
    "\n",
    "The new [Assistants API](https://platform.openai.com/docs/assistants/overview) is a stateful evoltuion of our [Chat Completions API](https://platform.openai.com/docs/guides/text-generation/chat-completions-api) meant to simplify the creation of assistant-like experiences, and enable developer access to powerful tools like Code Interpreter and Knowledge Retreival.\n",
    "\n",
    "## Assistanst API vs Chat Completions API\n",
    "TODO...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python SDK Setup\n",
    "\n",
    "> **Note**\n",
    "> We've updated our Python SDK to add support for the Assistants API functions, so you'll need to update it to the latest version (`1.1.1` at time of writing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And make sure it's up to date by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show openai | grep Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Example with Assistants API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll first define a simple utility function to better visualze the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def show_json(obj):\n",
    "    return json.loads(obj.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can begin by creating an assistant! We'll create a Math Tutor just like in our [docs](https://platform.openai.com/docs/assistants/overview). We'll specify the following:\n",
    "- `name`: a high-level name for our Assistant.\n",
    "- `instructions`: the behavior for our Assistant (similar to the `system` prompt in Chat Completions)\n",
    "- `tools`: which tools to enable (in this case `code_interpreter`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'asst_ooPQXw1Jqx0DMH96PEmdvXrw',\n",
       " 'created_at': 1699473978,\n",
       " 'description': None,\n",
       " 'file_ids': [],\n",
       " 'instructions': 'You are a personal math tutor. Answer questions in a sentence or less.',\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4-1106-preview',\n",
       " 'name': 'Math Tutor',\n",
       " 'object': 'assistant',\n",
       " 'tools': []}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Math Tutor\",\n",
    "    instructions=\"You are a personal math tutor. Answer questions in a sentence or less.\",\n",
    "    model=\"gpt-4-1106-preview\",\n",
    ")\n",
    "show_json(assistant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create a new Thread and add a message to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'thread_mkOTQm2FbgnFbDwPcj3c25UD',\n",
       " 'created_at': 1699471265,\n",
       " 'metadata': {},\n",
       " 'object': 'thread'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread = client.beta.threads.create()\n",
    "show_json(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_PtotfCRWtqqNx8HtdCAGMHVN',\n",
       " 'assistant_id': None,\n",
       " 'content': [{'text': {'annotations': [],\n",
       "    'value': 'I need to solve the equation `3x + 11 = 14`. Can you help me?'},\n",
       "   'type': 'text'}],\n",
       " 'created_at': 1699471266,\n",
       " 'file_ids': [],\n",
       " 'metadata': {},\n",
       " 'object': 'thread.message',\n",
       " 'role': 'user',\n",
       " 'run_id': None,\n",
       " 'thread_id': 'thread_mkOTQm2FbgnFbDwPcj3c25UD'}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"I need to solve the equation `3x + 11 = 14`. Can you help me?\"\n",
    ")\n",
    "show_json(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how this Thread is **not** associated with the Assistant we just created! Threads exist independently from Assistants, which may be different from what you'd expect if you've used ChatGPT (where a thread is tied to a model/GPT).\n",
    "\n",
    "To get a completion from an Assistant for a given Thread, we must create a Run. Creating a Run will indicate to an Assistant it should look at the messages in the Thread and take action: either by adding a single response, or using tools. \n",
    "\n",
    "> **Note**\n",
    "> Runs are key difference between the Assistants API and Chat Completions API! While in Chat Completions the model will only ever respond with a single message, in the Assistants API a Run may result in an Assistant using one or multiple tools, and potentially adding multiple messages to the Thread.\n",
    "\n",
    "To get our Assistant to respond to the user, let's create the Run. As mentioned earlier, you must specify _both_ the Assistant _and_ the Thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'run_m4coeyi0QaOxTSvtHBMhD0P6',\n",
       " 'assistant_id': 'asst_ZMiruz2BFdAUDr5t3Aal0CsU',\n",
       " 'cancelled_at': None,\n",
       " 'completed_at': None,\n",
       " 'created_at': 1699471268,\n",
       " 'expires_at': 1699471868,\n",
       " 'failed_at': None,\n",
       " 'file_ids': [],\n",
       " 'instructions': 'You are a personal math tutor. Write and run code to answer math questions.',\n",
       " 'last_error': None,\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4-1106-preview',\n",
       " 'object': 'thread.run',\n",
       " 'required_action': None,\n",
       " 'started_at': None,\n",
       " 'status': 'queued',\n",
       " 'thread_id': 'thread_mkOTQm2FbgnFbDwPcj3c25UD',\n",
       " 'tools': [{'type': 'code_interpreter'}]}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    ")\n",
    "show_json(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike creating a completion in Chat Completions, creating a Run is an asynchronous operation. It will return immediately with the Run's metadata, which includes a `status` that will initially be set to `queued`. The `status` will be updated as the Assistant performs operations (like using tools and adding messages).\n",
    "\n",
    "To know when the Assistant has completed processing, we can poll the Run in a loop. (We will soon be adding support for streaming.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_on_run(run):\n",
    "    while not (run.status == \"completed\" or run.status == \"failed\"):\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id,\n",
    "        )\n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'run_m4coeyi0QaOxTSvtHBMhD0P6',\n",
       " 'assistant_id': 'asst_ZMiruz2BFdAUDr5t3Aal0CsU',\n",
       " 'cancelled_at': None,\n",
       " 'completed_at': 1699471273,\n",
       " 'created_at': 1699471268,\n",
       " 'expires_at': None,\n",
       " 'failed_at': None,\n",
       " 'file_ids': [],\n",
       " 'instructions': 'You are a personal math tutor. Write and run code to answer math questions.',\n",
       " 'last_error': None,\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4-1106-preview',\n",
       " 'object': 'thread.run',\n",
       " 'required_action': None,\n",
       " 'started_at': 1699471269,\n",
       " 'status': 'completed',\n",
       " 'thread_id': 'thread_mkOTQm2FbgnFbDwPcj3c25UD',\n",
       " 'tools': [{'type': 'code_interpreter'}]}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = wait_on_run(run)\n",
    "show_json(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the Run has completed we list the Messages in the Thread to see what got added by the Assistant!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'id': 'msg_hatP0z3rQTyIwV8BPFwBtQmw',\n",
       "   'assistant_id': 'asst_ZMiruz2BFdAUDr5t3Aal0CsU',\n",
       "   'content': [{'text': {'annotations': [],\n",
       "      'value': 'The solution to the equation \\\\(3x + 11 = 14\\\\) is \\\\(x = 1\\\\).'},\n",
       "     'type': 'text'}],\n",
       "   'created_at': 1699471273,\n",
       "   'file_ids': [],\n",
       "   'metadata': {},\n",
       "   'object': 'thread.message',\n",
       "   'role': 'assistant',\n",
       "   'run_id': 'run_m4coeyi0QaOxTSvtHBMhD0P6',\n",
       "   'thread_id': 'thread_mkOTQm2FbgnFbDwPcj3c25UD'},\n",
       "  {'id': 'msg_PtotfCRWtqqNx8HtdCAGMHVN',\n",
       "   'assistant_id': None,\n",
       "   'content': [{'text': {'annotations': [],\n",
       "      'value': 'I need to solve the equation `3x + 11 = 14`. Can you help me?'},\n",
       "     'type': 'text'}],\n",
       "   'created_at': 1699471266,\n",
       "   'file_ids': [],\n",
       "   'metadata': {},\n",
       "   'object': 'thread.message',\n",
       "   'role': 'user',\n",
       "   'run_id': None,\n",
       "   'thread_id': 'thread_mkOTQm2FbgnFbDwPcj3c25UD'}],\n",
       " 'object': 'list',\n",
       " 'first_id': 'msg_hatP0z3rQTyIwV8BPFwBtQmw',\n",
       " 'last_id': 'msg_PtotfCRWtqqNx8HtdCAGMHVN',\n",
       " 'has_more': False}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "show_json(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, Messages are ordered in reverse-chronological order – this was done so the results are always on the first `page` (since results can be paginated). Do keep a look out for this, since this is opposite to messages in the Chat Completions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's ask our Assistant to explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/ilan/Desktop/openai-cookbook/examples/assistants_api_overview.ipynb Cell 23\u001b[0m line \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ilan/Desktop/openai-cookbook/examples/assistants_api_overview.ipynb#X46sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m wait_on_run(run)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ilan/Desktop/openai-cookbook/examples/assistants_api_overview.ipynb#X46sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m messages \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mbeta\u001b[39m.\u001b[39mthreads\u001b[39m.\u001b[39mmessages\u001b[39m.\u001b[39mlist(thread_id\u001b[39m=\u001b[39mthread\u001b[39m.\u001b[39mid, order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39masc\u001b[39m\u001b[39m'\u001b[39m, after\u001b[39m=\u001b[39mmessage\u001b[39m.\u001b[39mid)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ilan/Desktop/openai-cookbook/examples/assistants_api_overview.ipynb#X46sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m show_json(messages\u001b[39m.\u001b[39;49mdata)\n",
      "\u001b[1;32m/Users/ilan/Desktop/openai-cookbook/examples/assistants_api_overview.ipynb Cell 23\u001b[0m line \u001b[0;36mshow_json\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ilan/Desktop/openai-cookbook/examples/assistants_api_overview.ipynb#X46sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshow_json\u001b[39m(obj):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ilan/Desktop/openai-cookbook/examples/assistants_api_overview.ipynb#X46sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m json\u001b[39m.\u001b[39mloads(obj\u001b[39m.\u001b[39;49mjson())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'json'"
     ]
    }
   ],
   "source": [
    "# Create a message to append to our thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Could you explain this to me?\"\n",
    ")\n",
    "\n",
    "# Execute our run\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    ")\n",
    "\n",
    "# Wait for completion\n",
    "wait_on_run(run)\n",
    "\n",
    "# Get all the messages added after our last user message\n",
    "messages = client.beta.threads.messages.list(thread_id=thread.id, order='asc', after=message.id)\n",
    "show_json(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may feel like a lot of steps to get a response back – however, once you've created your assistant you can re-use it anywhere without having to maintain its state or pass references! It will also show up in your [OpenAI Assistants](https://platform.openai.com/assistants) dashboard.\n",
    "\n",
    "You can also do all of the setup directly in the dashboard if you prefer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"1728\" alt=\"Screenshot 2023-11-08 at 3 08 50 PM\" src=\"https://github.com/ibigio/shell-ai/assets/25421602/f8002f51-d3e2-40e4-8ded-f619505ed21e\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how we could potentially put all of this together! Below is all the code you need to use an Assistant you've created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "MATH_ASSISTANT_ID = \"asst_ooPQXw1Jqx0DMH96PEmdvXrw\"\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def wait_on_run(thread, run):\n",
    "    while not (run.status == \"completed\" or run.status == \"failed\"):\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id,\n",
    "        )\n",
    "    return run\n",
    "\n",
    "def submit_message(assistant_id, thread, user_message):\n",
    "    message = client.beta.threads.messages.create(\n",
    "        thread_id=thread.id, role=\"user\", content=user_message\n",
    "    )\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant_id,\n",
    "    )\n",
    "    wait_on_run(thread, run)\n",
    "    messages = client.beta.threads.messages.list(\n",
    "        thread_id=thread.id, order=\"asc\", after=message.id\n",
    "    )\n",
    "    return [m.content[0].text.value for m in messages.data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = []\n",
    "for i in range(3):\n",
    "    threads.append(client.beta.threads.create())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Subtract 11 from both sides to get `3x = 3`, then divide both sides by 3 to solve for `x`, so `x = 1`.']\n",
      "['Linear algebra is the branch of mathematics that deals with vectors, vector spaces, linear transformations, and systems of linear equations, often represented using matrices.']\n",
      "['To make math more enjoyable, try to find aspects of it that relate to your interests, practice regularly to build confidence, or work with a tutor or friend to make the learning process more engaging and supportive.']\n"
     ]
    }
   ],
   "source": [
    "print(submit_message(MATH_ASSISTANT_ID, threads[0], \"I need to solve the equation `3x + 11 = 14`. Can you help me?\"))\n",
    "print(submit_message(MATH_ASSISTANT_ID, threads[1], \"Could you explain linear algebra to me?\"))\n",
    "print(submit_message(MATH_ASSISTANT_ID, threads[2], \"I don't like math. What can I do?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
